{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Cardiac Arrhythmia Multi-Class Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-8SZLaE9uxNc",
        "asu-bKyfuxNe",
        "0jLvBN7VuxNl",
        "-wChdqLxuxNn"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdiazg14/ML/blob/main/Cardiac_Arrhythmia_Multi_Class_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89flJ1s4uxNV"
      },
      "source": [
        "### Cardiac Arrhythmia Multy-Class Classification \n",
        "\n",
        "Analyze data and address missing data if there is any. \n",
        "\n",
        "Decide aboute a good evaluation strategy and justify your choice. \n",
        "\n",
        "Find the best parameters for the following classification models: \n",
        "- KNN classifcation \n",
        "- Logistic Regression\n",
        "- Linear Supprt Vector Machine\n",
        "- Kerenilzed Support Vector Machine\n",
        "- Decision Tree\n",
        "- Random Forest "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1HbqVIHuxNX"
      },
      "source": [
        "# 1. Data Reading\n",
        "Starting with reading the data file and creating a dataframe for putting the output of all the models that \n",
        " we will be running. The purpose of doing this is it will be easy for us to compare the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "rz7QyPg2uxNY",
        "outputId": "272bc9ec-62c2-49bf-a366-c9f1d77836e3"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn import preprocessing\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "data = pd.read_csv('cardiac_arrhythmia.csv')\n",
        "output = pd.DataFrame(index=None, columns=['model','train_Rsquare', 'test_Rsquare', 'train_MSE','test_MSE'])\n",
        "data.describe()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>sex</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>QRS_duration</th>\n",
              "      <th>P-R_interval</th>\n",
              "      <th>Q-T_interval</th>\n",
              "      <th>T_interval</th>\n",
              "      <th>P_interval</th>\n",
              "      <th>QRS</th>\n",
              "      <th>DI_Q_wave</th>\n",
              "      <th>DI_R_wave</th>\n",
              "      <th>DI_S_wave</th>\n",
              "      <th>DI_R'_wave</th>\n",
              "      <th>DI_S'_wave</th>\n",
              "      <th>DI_no_intrinsic_defelections</th>\n",
              "      <th>DI_Rag_R_wave</th>\n",
              "      <th>DI_Dip_deriv_R_wave</th>\n",
              "      <th>DI_Rag_P_wave</th>\n",
              "      <th>DI_Dip_deriv_P_wave</th>\n",
              "      <th>DI_Rag_T_wave</th>\n",
              "      <th>DI_Dip_deriv_T_wave</th>\n",
              "      <th>DII_Q_wave</th>\n",
              "      <th>DII_R_wave</th>\n",
              "      <th>DII_S_wave</th>\n",
              "      <th>DII_R'_wave</th>\n",
              "      <th>DII_S'_wave</th>\n",
              "      <th>DII_no_intrinsic_defelections</th>\n",
              "      <th>DII_Rag_R_wave</th>\n",
              "      <th>DII_Dip_deriv_R_wave</th>\n",
              "      <th>DII_Rag_P_wave</th>\n",
              "      <th>DII_Dip_deriv_P_wave</th>\n",
              "      <th>DII_Rag_T_wave</th>\n",
              "      <th>DII_Dip_deriv_T_wave</th>\n",
              "      <th>DIII_Q_wave</th>\n",
              "      <th>DIII_R_wave</th>\n",
              "      <th>DIII_S_wave</th>\n",
              "      <th>DIII_R'_wave</th>\n",
              "      <th>DIII_S'_wave</th>\n",
              "      <th>DIII_no_intrinsic_defelections</th>\n",
              "      <th>...</th>\n",
              "      <th>Amp_V3_Q_wave</th>\n",
              "      <th>Amp_V3_R_wave</th>\n",
              "      <th>Amp_V3_S_wave</th>\n",
              "      <th>Amp_V3_R'_wave</th>\n",
              "      <th>Amp_V3_S'_wave</th>\n",
              "      <th>Amp_V3_P_wave</th>\n",
              "      <th>Amp_V3_T_wave</th>\n",
              "      <th>Amp_V3_QRSA</th>\n",
              "      <th>Amp_V3_QRSTA</th>\n",
              "      <th>Amp_V4_JJ_wave</th>\n",
              "      <th>Amp_V4_Q_wave</th>\n",
              "      <th>Amp_V4_R_wave</th>\n",
              "      <th>Amp_V4_S_wave</th>\n",
              "      <th>Amp_V4_R'_wave</th>\n",
              "      <th>Amp_V4_S'_wave</th>\n",
              "      <th>Amp_V4_P_wave</th>\n",
              "      <th>Amp_V4_T_wave</th>\n",
              "      <th>Amp_V4_QRSA</th>\n",
              "      <th>Amp_V4_QRSTA</th>\n",
              "      <th>Amp_V5_JJ_wave</th>\n",
              "      <th>Amp_V5_Q_wave</th>\n",
              "      <th>Amp_V5_R_wave</th>\n",
              "      <th>Amp_V5_S_wave</th>\n",
              "      <th>Amp_V5_R'_wave</th>\n",
              "      <th>Amp_V5_S'_wave</th>\n",
              "      <th>Amp_V5_P_wave</th>\n",
              "      <th>Amp_V5_T_wave</th>\n",
              "      <th>Amp_V5_QRSA</th>\n",
              "      <th>Amp_V5_QRSTA</th>\n",
              "      <th>Amp_V6_JJ_wave</th>\n",
              "      <th>Amp_V6_Q_wave</th>\n",
              "      <th>Amp_V6_R_wave</th>\n",
              "      <th>Amp_V6_S_wave</th>\n",
              "      <th>Amp_V6_R'_wave</th>\n",
              "      <th>Amp_V6_S'_wave</th>\n",
              "      <th>Amp_V6_P_wave</th>\n",
              "      <th>Amp_V6_T_wave</th>\n",
              "      <th>Amp_V6_QRSA</th>\n",
              "      <th>Amp_V6_QRSTA</th>\n",
              "      <th>cardiac_arrhythmia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.00000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>46.471239</td>\n",
              "      <td>0.550885</td>\n",
              "      <td>166.188053</td>\n",
              "      <td>68.170354</td>\n",
              "      <td>88.920354</td>\n",
              "      <td>155.152655</td>\n",
              "      <td>367.207965</td>\n",
              "      <td>169.949115</td>\n",
              "      <td>90.004425</td>\n",
              "      <td>33.676991</td>\n",
              "      <td>5.628319</td>\n",
              "      <td>51.628319</td>\n",
              "      <td>20.920354</td>\n",
              "      <td>0.141593</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.035398</td>\n",
              "      <td>0.002212</td>\n",
              "      <td>0.011062</td>\n",
              "      <td>0.011062</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.008850</td>\n",
              "      <td>5.619469</td>\n",
              "      <td>54.336283</td>\n",
              "      <td>20.59292</td>\n",
              "      <td>0.433628</td>\n",
              "      <td>0.150442</td>\n",
              "      <td>31.637168</td>\n",
              "      <td>0.017699</td>\n",
              "      <td>0.028761</td>\n",
              "      <td>0.002212</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.015487</td>\n",
              "      <td>16.026549</td>\n",
              "      <td>41.982301</td>\n",
              "      <td>20.327434</td>\n",
              "      <td>2.300885</td>\n",
              "      <td>0.318584</td>\n",
              "      <td>30.513274</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.653540</td>\n",
              "      <td>8.039602</td>\n",
              "      <td>-10.150664</td>\n",
              "      <td>0.032965</td>\n",
              "      <td>-0.013496</td>\n",
              "      <td>0.226770</td>\n",
              "      <td>3.894690</td>\n",
              "      <td>-8.269027</td>\n",
              "      <td>32.422788</td>\n",
              "      <td>0.001106</td>\n",
              "      <td>-0.297566</td>\n",
              "      <td>11.839381</td>\n",
              "      <td>-7.034513</td>\n",
              "      <td>0.025664</td>\n",
              "      <td>-0.002876</td>\n",
              "      <td>0.547788</td>\n",
              "      <td>2.535841</td>\n",
              "      <td>10.081195</td>\n",
              "      <td>33.328540</td>\n",
              "      <td>-0.285398</td>\n",
              "      <td>-0.277212</td>\n",
              "      <td>11.369912</td>\n",
              "      <td>-3.607522</td>\n",
              "      <td>0.016814</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.546681</td>\n",
              "      <td>1.722124</td>\n",
              "      <td>17.840044</td>\n",
              "      <td>32.871460</td>\n",
              "      <td>-0.302434</td>\n",
              "      <td>-0.278982</td>\n",
              "      <td>9.048009</td>\n",
              "      <td>-1.457301</td>\n",
              "      <td>0.003982</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.514823</td>\n",
              "      <td>1.222345</td>\n",
              "      <td>19.326106</td>\n",
              "      <td>29.473230</td>\n",
              "      <td>3.880531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.466631</td>\n",
              "      <td>0.497955</td>\n",
              "      <td>37.170340</td>\n",
              "      <td>16.590803</td>\n",
              "      <td>15.364394</td>\n",
              "      <td>44.842283</td>\n",
              "      <td>33.385421</td>\n",
              "      <td>35.633072</td>\n",
              "      <td>25.826643</td>\n",
              "      <td>45.431434</td>\n",
              "      <td>10.650001</td>\n",
              "      <td>18.249901</td>\n",
              "      <td>20.541728</td>\n",
              "      <td>1.569483</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.046393</td>\n",
              "      <td>0.047036</td>\n",
              "      <td>0.104708</td>\n",
              "      <td>0.104708</td>\n",
              "      <td>0.066445</td>\n",
              "      <td>0.066445</td>\n",
              "      <td>0.093759</td>\n",
              "      <td>11.220680</td>\n",
              "      <td>17.248213</td>\n",
              "      <td>21.06105</td>\n",
              "      <td>3.093161</td>\n",
              "      <td>2.692591</td>\n",
              "      <td>9.624951</td>\n",
              "      <td>0.132002</td>\n",
              "      <td>0.167319</td>\n",
              "      <td>0.047036</td>\n",
              "      <td>0.066445</td>\n",
              "      <td>0.066445</td>\n",
              "      <td>0.123615</td>\n",
              "      <td>21.906457</td>\n",
              "      <td>23.106034</td>\n",
              "      <td>25.365424</td>\n",
              "      <td>9.212818</td>\n",
              "      <td>3.124229</td>\n",
              "      <td>18.359850</td>\n",
              "      <td>...</td>\n",
              "      <td>3.414085</td>\n",
              "      <td>5.279719</td>\n",
              "      <td>7.066568</td>\n",
              "      <td>0.390403</td>\n",
              "      <td>0.264398</td>\n",
              "      <td>0.548988</td>\n",
              "      <td>2.990809</td>\n",
              "      <td>32.157008</td>\n",
              "      <td>37.362289</td>\n",
              "      <td>1.015566</td>\n",
              "      <td>1.758544</td>\n",
              "      <td>5.917391</td>\n",
              "      <td>5.061472</td>\n",
              "      <td>0.166763</td>\n",
              "      <td>0.046287</td>\n",
              "      <td>0.426941</td>\n",
              "      <td>2.429776</td>\n",
              "      <td>25.074695</td>\n",
              "      <td>34.361665</td>\n",
              "      <td>0.675060</td>\n",
              "      <td>0.992472</td>\n",
              "      <td>4.793656</td>\n",
              "      <td>2.850633</td>\n",
              "      <td>0.275907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.370548</td>\n",
              "      <td>1.708190</td>\n",
              "      <td>16.445472</td>\n",
              "      <td>24.421643</td>\n",
              "      <td>0.603551</td>\n",
              "      <td>0.548876</td>\n",
              "      <td>3.472862</td>\n",
              "      <td>2.002430</td>\n",
              "      <td>0.050118</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.347531</td>\n",
              "      <td>1.426052</td>\n",
              "      <td>13.503922</td>\n",
              "      <td>18.493927</td>\n",
              "      <td>4.407097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>232.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-172.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-32.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-48.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.600000</td>\n",
              "      <td>-3.100000</td>\n",
              "      <td>-11.800000</td>\n",
              "      <td>-242.400000</td>\n",
              "      <td>-146.200000</td>\n",
              "      <td>-3.200000</td>\n",
              "      <td>-20.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-42.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.900000</td>\n",
              "      <td>-2.600000</td>\n",
              "      <td>-8.200000</td>\n",
              "      <td>-124.800000</td>\n",
              "      <td>-161.400000</td>\n",
              "      <td>-4.800000</td>\n",
              "      <td>-14.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-30.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.900000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>-56.800000</td>\n",
              "      <td>-63.600000</td>\n",
              "      <td>-5.600000</td>\n",
              "      <td>-4.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-28.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>-44.200000</td>\n",
              "      <td>-38.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>-13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-19.525000</td>\n",
              "      <td>9.850000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.875000</td>\n",
              "      <td>-9.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>-0.925000</td>\n",
              "      <td>11.275000</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>-4.725000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>8.675000</td>\n",
              "      <td>15.375000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.425000</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>-2.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>11.450000</td>\n",
              "      <td>17.550000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>47.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>367.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>20.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.050000</td>\n",
              "      <td>-8.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>-4.700000</td>\n",
              "      <td>32.550000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>11.400000</td>\n",
              "      <td>32.750000</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>18.350000</td>\n",
              "      <td>30.350000</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>-1.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.350000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>27.900000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>384.000000</td>\n",
              "      <td>179.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>36.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>-5.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>5.525000</td>\n",
              "      <td>7.625000</td>\n",
              "      <td>56.025000</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.100000</td>\n",
              "      <td>-3.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>25.050000</td>\n",
              "      <td>52.325000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.125000</td>\n",
              "      <td>-1.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>27.900000</td>\n",
              "      <td>48.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>25.825000</td>\n",
              "      <td>41.125000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>83.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>188.000000</td>\n",
              "      <td>524.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>381.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>92.00000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>18.800000</td>\n",
              "      <td>165.400000</td>\n",
              "      <td>137.800000</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>15.600000</td>\n",
              "      <td>103.400000</td>\n",
              "      <td>182.300000</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>8.300000</td>\n",
              "      <td>82.100000</td>\n",
              "      <td>127.900000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>88.800000</td>\n",
              "      <td>115.900000</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 275 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age         sex  ...  Amp_V6_QRSTA  cardiac_arrhythmia\n",
              "count  452.000000  452.000000  ...    452.000000          452.000000\n",
              "mean    46.471239    0.550885  ...     29.473230            3.880531\n",
              "std     16.466631    0.497955  ...     18.493927            4.407097\n",
              "min      0.000000    0.000000  ...    -38.600000            1.000000\n",
              "25%     36.000000    0.000000  ...     17.550000            1.000000\n",
              "50%     47.000000    1.000000  ...     27.900000            1.000000\n",
              "75%     58.000000    1.000000  ...     41.125000            6.000000\n",
              "max     83.000000    1.000000  ...    115.900000           16.000000\n",
              "\n",
              "[8 rows x 275 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "Y_rFptkrygfx",
        "outputId": "4f5d4020-adbb-4700-98c9-3e6f2965f6bc"
      },
      "source": [
        "data"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>sex</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>QRS_duration</th>\n",
              "      <th>P-R_interval</th>\n",
              "      <th>Q-T_interval</th>\n",
              "      <th>T_interval</th>\n",
              "      <th>P_interval</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>J</th>\n",
              "      <th>HR</th>\n",
              "      <th>DI_Q_wave</th>\n",
              "      <th>DI_R_wave</th>\n",
              "      <th>DI_S_wave</th>\n",
              "      <th>DI_R'_wave</th>\n",
              "      <th>DI_S'_wave</th>\n",
              "      <th>DI_no_intrinsic_defelections</th>\n",
              "      <th>DI_Rag_R_wave</th>\n",
              "      <th>DI_Dip_deriv_R_wave</th>\n",
              "      <th>DI_Rag_P_wave</th>\n",
              "      <th>DI_Dip_deriv_P_wave</th>\n",
              "      <th>DI_Rag_T_wave</th>\n",
              "      <th>DI_Dip_deriv_T_wave</th>\n",
              "      <th>DII_Q_wave</th>\n",
              "      <th>DII_R_wave</th>\n",
              "      <th>DII_S_wave</th>\n",
              "      <th>DII_R'_wave</th>\n",
              "      <th>DII_S'_wave</th>\n",
              "      <th>DII_no_intrinsic_defelections</th>\n",
              "      <th>DII_Rag_R_wave</th>\n",
              "      <th>DII_Dip_deriv_R_wave</th>\n",
              "      <th>DII_Rag_P_wave</th>\n",
              "      <th>DII_Dip_deriv_P_wave</th>\n",
              "      <th>DII_Rag_T_wave</th>\n",
              "      <th>DII_Dip_deriv_T_wave</th>\n",
              "      <th>DIII_Q_wave</th>\n",
              "      <th>...</th>\n",
              "      <th>Amp_V3_Q_wave</th>\n",
              "      <th>Amp_V3_R_wave</th>\n",
              "      <th>Amp_V3_S_wave</th>\n",
              "      <th>Amp_V3_R'_wave</th>\n",
              "      <th>Amp_V3_S'_wave</th>\n",
              "      <th>Amp_V3_P_wave</th>\n",
              "      <th>Amp_V3_T_wave</th>\n",
              "      <th>Amp_V3_QRSA</th>\n",
              "      <th>Amp_V3_QRSTA</th>\n",
              "      <th>Amp_V4_JJ_wave</th>\n",
              "      <th>Amp_V4_Q_wave</th>\n",
              "      <th>Amp_V4_R_wave</th>\n",
              "      <th>Amp_V4_S_wave</th>\n",
              "      <th>Amp_V4_R'_wave</th>\n",
              "      <th>Amp_V4_S'_wave</th>\n",
              "      <th>Amp_V4_P_wave</th>\n",
              "      <th>Amp_V4_T_wave</th>\n",
              "      <th>Amp_V4_QRSA</th>\n",
              "      <th>Amp_V4_QRSTA</th>\n",
              "      <th>Amp_V5_JJ_wave</th>\n",
              "      <th>Amp_V5_Q_wave</th>\n",
              "      <th>Amp_V5_R_wave</th>\n",
              "      <th>Amp_V5_S_wave</th>\n",
              "      <th>Amp_V5_R'_wave</th>\n",
              "      <th>Amp_V5_S'_wave</th>\n",
              "      <th>Amp_V5_P_wave</th>\n",
              "      <th>Amp_V5_T_wave</th>\n",
              "      <th>Amp_V5_QRSA</th>\n",
              "      <th>Amp_V5_QRSTA</th>\n",
              "      <th>Amp_V6_JJ_wave</th>\n",
              "      <th>Amp_V6_Q_wave</th>\n",
              "      <th>Amp_V6_R_wave</th>\n",
              "      <th>Amp_V6_S_wave</th>\n",
              "      <th>Amp_V6_R'_wave</th>\n",
              "      <th>Amp_V6_S'_wave</th>\n",
              "      <th>Amp_V6_P_wave</th>\n",
              "      <th>Amp_V6_T_wave</th>\n",
              "      <th>Amp_V6_QRSA</th>\n",
              "      <th>Amp_V6_QRSTA</th>\n",
              "      <th>cardiac_arrhythmia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>91</td>\n",
              "      <td>193</td>\n",
              "      <td>371</td>\n",
              "      <td>174</td>\n",
              "      <td>121</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>64</td>\n",
              "      <td>-2</td>\n",
              "      <td>?</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>52.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.1</td>\n",
              "      <td>17.7</td>\n",
              "      <td>70.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>62.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>23.3</td>\n",
              "      <td>49.4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>174</td>\n",
              "      <td>401</td>\n",
              "      <td>149</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>37</td>\n",
              "      <td>-17</td>\n",
              "      <td>31</td>\n",
              "      <td>?</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>27.7</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.8</td>\n",
              "      <td>34.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>38.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>163</td>\n",
              "      <td>386</td>\n",
              "      <td>185</td>\n",
              "      <td>102</td>\n",
              "      <td>96</td>\n",
              "      <td>34</td>\n",
              "      <td>70</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>202</td>\n",
              "      <td>380</td>\n",
              "      <td>179</td>\n",
              "      <td>143</td>\n",
              "      <td>28</td>\n",
              "      <td>11</td>\n",
              "      <td>-5</td>\n",
              "      <td>20</td>\n",
              "      <td>?</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>28.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>34.6</td>\n",
              "      <td>61.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>181</td>\n",
              "      <td>360</td>\n",
              "      <td>177</td>\n",
              "      <td>103</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>61</td>\n",
              "      <td>3</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>16.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.4</td>\n",
              "      <td>62.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>80</td>\n",
              "      <td>199</td>\n",
              "      <td>382</td>\n",
              "      <td>154</td>\n",
              "      <td>117</td>\n",
              "      <td>-37</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>-27</td>\n",
              "      <td>?</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>-9.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-22.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-10.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-20.1</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>-8.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>85</td>\n",
              "      <td>100</td>\n",
              "      <td>137</td>\n",
              "      <td>361</td>\n",
              "      <td>201</td>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>66</td>\n",
              "      <td>52</td>\n",
              "      <td>79</td>\n",
              "      <td>?</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-5.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>10.8</td>\n",
              "      <td>27.7</td>\n",
              "      <td>137.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>5.9</td>\n",
              "      <td>69.2</td>\n",
              "      <td>129.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.2</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>50.7</td>\n",
              "      <td>82.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>62.4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>68</td>\n",
              "      <td>108</td>\n",
              "      <td>176</td>\n",
              "      <td>365</td>\n",
              "      <td>194</td>\n",
              "      <td>116</td>\n",
              "      <td>-85</td>\n",
              "      <td>-19</td>\n",
              "      <td>-61</td>\n",
              "      <td>-70</td>\n",
              "      <td>84</td>\n",
              "      <td>84</td>\n",
              "      <td>16</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.3</td>\n",
              "      <td>-34.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-75.7</td>\n",
              "      <td>-146.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>-36.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-71.2</td>\n",
              "      <td>-161.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>-30.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-39.6</td>\n",
              "      <td>-63.6</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.3</td>\n",
              "      <td>-28.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-44.2</td>\n",
              "      <td>-33.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>93</td>\n",
              "      <td>106</td>\n",
              "      <td>386</td>\n",
              "      <td>218</td>\n",
              "      <td>63</td>\n",
              "      <td>54</td>\n",
              "      <td>29</td>\n",
              "      <td>-22</td>\n",
              "      <td>43</td>\n",
              "      <td>103</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.9</td>\n",
              "      <td>94.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.9</td>\n",
              "      <td>-6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.8</td>\n",
              "      <td>17.5</td>\n",
              "      <td>56.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.7</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>25.0</td>\n",
              "      <td>46.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>79</td>\n",
              "      <td>127</td>\n",
              "      <td>364</td>\n",
              "      <td>138</td>\n",
              "      <td>78</td>\n",
              "      <td>28</td>\n",
              "      <td>79</td>\n",
              "      <td>52</td>\n",
              "      <td>47</td>\n",
              "      <td>?</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>38.3</td>\n",
              "      <td>60.9</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.6</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>44.0</td>\n",
              "      <td>60.8</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.7</td>\n",
              "      <td>26.7</td>\n",
              "      <td>38.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>21.3</td>\n",
              "      <td>32.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows Ã— 280 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  sex  height  ...  Amp_V6_QRSA  Amp_V6_QRSTA  cardiac_arrhythmia\n",
              "0     75    0     190  ...         23.3          49.4                   8\n",
              "1     56    1     165  ...         20.4          38.8                   6\n",
              "2     54    0     172  ...         12.3          49.0                  10\n",
              "3     55    0     175  ...         34.6          61.6                   1\n",
              "4     75    0     190  ...         25.4          62.8                   7\n",
              "..   ...  ...     ...  ...          ...           ...                 ...\n",
              "447   53    1     160  ...         -4.4          -0.5                   1\n",
              "448   37    0     190  ...         38.0          62.4                  10\n",
              "449   36    0     166  ...        -44.2         -33.2                   2\n",
              "450   32    1     155  ...         25.0          46.6                   1\n",
              "451   78    1     160  ...         21.3          32.8                   1\n",
              "\n",
              "[452 rows x 280 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ub6i53FuxNZ"
      },
      "source": [
        "# Handling the missing value\n",
        "While going through the dataset we observed that out of 279 columns 5 columns have missing value in the form of '?'.\n",
        "The approach which we will following is, first replacing '?' with numpy NAN and then imputing the mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUvb6KTCuxNZ"
      },
      "source": [
        "import numpy as np\n",
        "data['J'] = data['J'].replace('?',np.NaN)\n",
        "data['HR'] = data['HR'].replace('?',np.NaN)\n",
        "data['P'] = data['P'].replace('?',np.NaN)\n",
        "data['T'] = data['T'].replace('?',np.NaN)\n",
        "data['QRST'] = data['QRST'].replace('?',np.NaN)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "cPX3hUreyzJ7",
        "outputId": "abe2bc22-85a0-4bd2-df57-877bb3938f51"
      },
      "source": [
        "Data_X"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>sex</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>QRS_duration</th>\n",
              "      <th>P-R_interval</th>\n",
              "      <th>Q-T_interval</th>\n",
              "      <th>T_interval</th>\n",
              "      <th>P_interval</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>J</th>\n",
              "      <th>HR</th>\n",
              "      <th>DI_Q_wave</th>\n",
              "      <th>DI_R_wave</th>\n",
              "      <th>DI_S_wave</th>\n",
              "      <th>DI_R'_wave</th>\n",
              "      <th>DI_S'_wave</th>\n",
              "      <th>DI_no_intrinsic_defelections</th>\n",
              "      <th>DI_Rag_R_wave</th>\n",
              "      <th>DI_Dip_deriv_R_wave</th>\n",
              "      <th>DI_Rag_P_wave</th>\n",
              "      <th>DI_Dip_deriv_P_wave</th>\n",
              "      <th>DI_Rag_T_wave</th>\n",
              "      <th>DI_Dip_deriv_T_wave</th>\n",
              "      <th>DII_Q_wave</th>\n",
              "      <th>DII_R_wave</th>\n",
              "      <th>DII_S_wave</th>\n",
              "      <th>DII_R'_wave</th>\n",
              "      <th>DII_S'_wave</th>\n",
              "      <th>DII_no_intrinsic_defelections</th>\n",
              "      <th>DII_Rag_R_wave</th>\n",
              "      <th>DII_Dip_deriv_R_wave</th>\n",
              "      <th>DII_Rag_P_wave</th>\n",
              "      <th>DII_Dip_deriv_P_wave</th>\n",
              "      <th>DII_Rag_T_wave</th>\n",
              "      <th>DII_Dip_deriv_T_wave</th>\n",
              "      <th>DIII_Q_wave</th>\n",
              "      <th>...</th>\n",
              "      <th>Amp_V3_JJ_wave</th>\n",
              "      <th>Amp_V3_Q_wave</th>\n",
              "      <th>Amp_V3_R_wave</th>\n",
              "      <th>Amp_V3_S_wave</th>\n",
              "      <th>Amp_V3_R'_wave</th>\n",
              "      <th>Amp_V3_S'_wave</th>\n",
              "      <th>Amp_V3_P_wave</th>\n",
              "      <th>Amp_V3_T_wave</th>\n",
              "      <th>Amp_V3_QRSA</th>\n",
              "      <th>Amp_V3_QRSTA</th>\n",
              "      <th>Amp_V4_JJ_wave</th>\n",
              "      <th>Amp_V4_Q_wave</th>\n",
              "      <th>Amp_V4_R_wave</th>\n",
              "      <th>Amp_V4_S_wave</th>\n",
              "      <th>Amp_V4_R'_wave</th>\n",
              "      <th>Amp_V4_S'_wave</th>\n",
              "      <th>Amp_V4_P_wave</th>\n",
              "      <th>Amp_V4_T_wave</th>\n",
              "      <th>Amp_V4_QRSA</th>\n",
              "      <th>Amp_V4_QRSTA</th>\n",
              "      <th>Amp_V5_JJ_wave</th>\n",
              "      <th>Amp_V5_Q_wave</th>\n",
              "      <th>Amp_V5_R_wave</th>\n",
              "      <th>Amp_V5_S_wave</th>\n",
              "      <th>Amp_V5_R'_wave</th>\n",
              "      <th>Amp_V5_S'_wave</th>\n",
              "      <th>Amp_V5_P_wave</th>\n",
              "      <th>Amp_V5_T_wave</th>\n",
              "      <th>Amp_V5_QRSA</th>\n",
              "      <th>Amp_V5_QRSTA</th>\n",
              "      <th>Amp_V6_JJ_wave</th>\n",
              "      <th>Amp_V6_Q_wave</th>\n",
              "      <th>Amp_V6_R_wave</th>\n",
              "      <th>Amp_V6_S_wave</th>\n",
              "      <th>Amp_V6_R'_wave</th>\n",
              "      <th>Amp_V6_S'_wave</th>\n",
              "      <th>Amp_V6_P_wave</th>\n",
              "      <th>Amp_V6_T_wave</th>\n",
              "      <th>Amp_V6_QRSA</th>\n",
              "      <th>Amp_V6_QRSTA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>91</td>\n",
              "      <td>193</td>\n",
              "      <td>371</td>\n",
              "      <td>174</td>\n",
              "      <td>121</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>64</td>\n",
              "      <td>-2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>52.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.1</td>\n",
              "      <td>17.7</td>\n",
              "      <td>70.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>62.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>23.3</td>\n",
              "      <td>49.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>174</td>\n",
              "      <td>401</td>\n",
              "      <td>149</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>37</td>\n",
              "      <td>-17</td>\n",
              "      <td>31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>27.7</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.8</td>\n",
              "      <td>34.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>38.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>163</td>\n",
              "      <td>386</td>\n",
              "      <td>185</td>\n",
              "      <td>102</td>\n",
              "      <td>96</td>\n",
              "      <td>34</td>\n",
              "      <td>70</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>202</td>\n",
              "      <td>380</td>\n",
              "      <td>179</td>\n",
              "      <td>143</td>\n",
              "      <td>28</td>\n",
              "      <td>11</td>\n",
              "      <td>-5</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>...</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>28.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>34.6</td>\n",
              "      <td>61.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>181</td>\n",
              "      <td>360</td>\n",
              "      <td>177</td>\n",
              "      <td>103</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>61</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>16.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.4</td>\n",
              "      <td>62.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>80</td>\n",
              "      <td>199</td>\n",
              "      <td>382</td>\n",
              "      <td>154</td>\n",
              "      <td>117</td>\n",
              "      <td>-37</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>-27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>-9.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-22.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-10.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-20.1</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>-8.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>85</td>\n",
              "      <td>100</td>\n",
              "      <td>137</td>\n",
              "      <td>361</td>\n",
              "      <td>201</td>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>66</td>\n",
              "      <td>52</td>\n",
              "      <td>79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-5.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>10.8</td>\n",
              "      <td>27.7</td>\n",
              "      <td>137.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>5.9</td>\n",
              "      <td>69.2</td>\n",
              "      <td>129.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.2</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>50.7</td>\n",
              "      <td>82.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>62.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>68</td>\n",
              "      <td>108</td>\n",
              "      <td>176</td>\n",
              "      <td>365</td>\n",
              "      <td>194</td>\n",
              "      <td>116</td>\n",
              "      <td>-85</td>\n",
              "      <td>-19</td>\n",
              "      <td>-61</td>\n",
              "      <td>-70</td>\n",
              "      <td>84</td>\n",
              "      <td>84</td>\n",
              "      <td>16</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.3</td>\n",
              "      <td>-34.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-75.7</td>\n",
              "      <td>-146.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>-36.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-71.2</td>\n",
              "      <td>-161.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>-30.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-39.6</td>\n",
              "      <td>-63.6</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.3</td>\n",
              "      <td>-28.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-44.2</td>\n",
              "      <td>-33.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>93</td>\n",
              "      <td>106</td>\n",
              "      <td>386</td>\n",
              "      <td>218</td>\n",
              "      <td>63</td>\n",
              "      <td>54</td>\n",
              "      <td>29</td>\n",
              "      <td>-22</td>\n",
              "      <td>43</td>\n",
              "      <td>103</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.9</td>\n",
              "      <td>94.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.9</td>\n",
              "      <td>-6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.8</td>\n",
              "      <td>17.5</td>\n",
              "      <td>56.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.7</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>25.0</td>\n",
              "      <td>46.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>79</td>\n",
              "      <td>127</td>\n",
              "      <td>364</td>\n",
              "      <td>138</td>\n",
              "      <td>78</td>\n",
              "      <td>28</td>\n",
              "      <td>79</td>\n",
              "      <td>52</td>\n",
              "      <td>47</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>38.3</td>\n",
              "      <td>60.9</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.6</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>44.0</td>\n",
              "      <td>60.8</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.7</td>\n",
              "      <td>26.7</td>\n",
              "      <td>38.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>21.3</td>\n",
              "      <td>32.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows Ã— 279 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  sex  height  ...  Amp_V6_T_wave  Amp_V6_QRSA  Amp_V6_QRSTA\n",
              "0     75    0     190  ...            2.9         23.3          49.4\n",
              "1     56    1     165  ...            2.1         20.4          38.8\n",
              "2     54    0     172  ...            3.4         12.3          49.0\n",
              "3     55    0     175  ...            2.6         34.6          61.6\n",
              "4     75    0     190  ...            3.9         25.4          62.8\n",
              "..   ...  ...     ...  ...            ...          ...           ...\n",
              "447   53    1     160  ...            0.6         -4.4          -0.5\n",
              "448   37    0     190  ...            2.4         38.0          62.4\n",
              "449   36    0     166  ...            1.0        -44.2         -33.2\n",
              "450   32    1     155  ...            2.4         25.0          46.6\n",
              "451   78    1     160  ...            1.6         21.3          32.8\n",
              "\n",
              "[452 rows x 279 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE8gY7TtuxNZ"
      },
      "source": [
        "# Spliting the dataset\n",
        "Segregating the whole dataset into X and Y "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqzpQaOKuxNZ"
      },
      "source": [
        "Data_Y = data.cardiac_arrhythmia.values.ravel()\n",
        "Data_X=data.drop('cardiac_arrhythmia', 1)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xGiLW-PuxNa",
        "outputId": "04230df2-6e55-4695-c061-f07d60a7171d"
      },
      "source": [
        "np.unique(Data_Y, return_counts=True)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 14, 15, 16]),\n",
              " array([245,  44,  15,  15,  13,  25,   3,   2,   9,  50,   4,   5,  22]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "est4rxeaywPp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkjqsxjDuxNa"
      },
      "source": [
        "# Drop column\n",
        "We can observe that column J have a lot of missing value. It will not be a good practice to impute mean values in this column.\n",
        "Better option will be that we drop this column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "0YtVzahEuxNa",
        "outputId": "c40723ec-722e-4977-f22f-8e59c0cbffd5"
      },
      "source": [
        "Data_X.drop(columns=['J'])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>sex</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>QRS_duration</th>\n",
              "      <th>P-R_interval</th>\n",
              "      <th>Q-T_interval</th>\n",
              "      <th>T_interval</th>\n",
              "      <th>P_interval</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>HR</th>\n",
              "      <th>DI_Q_wave</th>\n",
              "      <th>DI_R_wave</th>\n",
              "      <th>DI_S_wave</th>\n",
              "      <th>DI_R'_wave</th>\n",
              "      <th>DI_S'_wave</th>\n",
              "      <th>DI_no_intrinsic_defelections</th>\n",
              "      <th>DI_Rag_R_wave</th>\n",
              "      <th>DI_Dip_deriv_R_wave</th>\n",
              "      <th>DI_Rag_P_wave</th>\n",
              "      <th>DI_Dip_deriv_P_wave</th>\n",
              "      <th>DI_Rag_T_wave</th>\n",
              "      <th>DI_Dip_deriv_T_wave</th>\n",
              "      <th>DII_Q_wave</th>\n",
              "      <th>DII_R_wave</th>\n",
              "      <th>DII_S_wave</th>\n",
              "      <th>DII_R'_wave</th>\n",
              "      <th>DII_S'_wave</th>\n",
              "      <th>DII_no_intrinsic_defelections</th>\n",
              "      <th>DII_Rag_R_wave</th>\n",
              "      <th>DII_Dip_deriv_R_wave</th>\n",
              "      <th>DII_Rag_P_wave</th>\n",
              "      <th>DII_Dip_deriv_P_wave</th>\n",
              "      <th>DII_Rag_T_wave</th>\n",
              "      <th>DII_Dip_deriv_T_wave</th>\n",
              "      <th>DIII_Q_wave</th>\n",
              "      <th>DIII_R_wave</th>\n",
              "      <th>...</th>\n",
              "      <th>Amp_V3_JJ_wave</th>\n",
              "      <th>Amp_V3_Q_wave</th>\n",
              "      <th>Amp_V3_R_wave</th>\n",
              "      <th>Amp_V3_S_wave</th>\n",
              "      <th>Amp_V3_R'_wave</th>\n",
              "      <th>Amp_V3_S'_wave</th>\n",
              "      <th>Amp_V3_P_wave</th>\n",
              "      <th>Amp_V3_T_wave</th>\n",
              "      <th>Amp_V3_QRSA</th>\n",
              "      <th>Amp_V3_QRSTA</th>\n",
              "      <th>Amp_V4_JJ_wave</th>\n",
              "      <th>Amp_V4_Q_wave</th>\n",
              "      <th>Amp_V4_R_wave</th>\n",
              "      <th>Amp_V4_S_wave</th>\n",
              "      <th>Amp_V4_R'_wave</th>\n",
              "      <th>Amp_V4_S'_wave</th>\n",
              "      <th>Amp_V4_P_wave</th>\n",
              "      <th>Amp_V4_T_wave</th>\n",
              "      <th>Amp_V4_QRSA</th>\n",
              "      <th>Amp_V4_QRSTA</th>\n",
              "      <th>Amp_V5_JJ_wave</th>\n",
              "      <th>Amp_V5_Q_wave</th>\n",
              "      <th>Amp_V5_R_wave</th>\n",
              "      <th>Amp_V5_S_wave</th>\n",
              "      <th>Amp_V5_R'_wave</th>\n",
              "      <th>Amp_V5_S'_wave</th>\n",
              "      <th>Amp_V5_P_wave</th>\n",
              "      <th>Amp_V5_T_wave</th>\n",
              "      <th>Amp_V5_QRSA</th>\n",
              "      <th>Amp_V5_QRSTA</th>\n",
              "      <th>Amp_V6_JJ_wave</th>\n",
              "      <th>Amp_V6_Q_wave</th>\n",
              "      <th>Amp_V6_R_wave</th>\n",
              "      <th>Amp_V6_S_wave</th>\n",
              "      <th>Amp_V6_R'_wave</th>\n",
              "      <th>Amp_V6_S'_wave</th>\n",
              "      <th>Amp_V6_P_wave</th>\n",
              "      <th>Amp_V6_T_wave</th>\n",
              "      <th>Amp_V6_QRSA</th>\n",
              "      <th>Amp_V6_QRSTA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>91</td>\n",
              "      <td>193</td>\n",
              "      <td>371</td>\n",
              "      <td>174</td>\n",
              "      <td>121</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>64</td>\n",
              "      <td>-2</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>40</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>52.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.1</td>\n",
              "      <td>17.7</td>\n",
              "      <td>70.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>62.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>23.3</td>\n",
              "      <td>49.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>174</td>\n",
              "      <td>401</td>\n",
              "      <td>149</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>37</td>\n",
              "      <td>-17</td>\n",
              "      <td>31</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>27.7</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.8</td>\n",
              "      <td>34.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>38.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>163</td>\n",
              "      <td>386</td>\n",
              "      <td>185</td>\n",
              "      <td>102</td>\n",
              "      <td>96</td>\n",
              "      <td>34</td>\n",
              "      <td>70</td>\n",
              "      <td>66</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>202</td>\n",
              "      <td>380</td>\n",
              "      <td>179</td>\n",
              "      <td>143</td>\n",
              "      <td>28</td>\n",
              "      <td>11</td>\n",
              "      <td>-5</td>\n",
              "      <td>20</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>28.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>34.6</td>\n",
              "      <td>61.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>181</td>\n",
              "      <td>360</td>\n",
              "      <td>177</td>\n",
              "      <td>103</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>61</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>36</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>16.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.4</td>\n",
              "      <td>62.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>80</td>\n",
              "      <td>199</td>\n",
              "      <td>382</td>\n",
              "      <td>154</td>\n",
              "      <td>117</td>\n",
              "      <td>-37</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>-27</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>-9.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-22.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-10.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-20.1</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>-8.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>85</td>\n",
              "      <td>100</td>\n",
              "      <td>137</td>\n",
              "      <td>361</td>\n",
              "      <td>201</td>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>66</td>\n",
              "      <td>52</td>\n",
              "      <td>79</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-5.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>10.8</td>\n",
              "      <td>27.7</td>\n",
              "      <td>137.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>5.9</td>\n",
              "      <td>69.2</td>\n",
              "      <td>129.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.2</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>50.7</td>\n",
              "      <td>82.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>62.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>68</td>\n",
              "      <td>108</td>\n",
              "      <td>176</td>\n",
              "      <td>365</td>\n",
              "      <td>194</td>\n",
              "      <td>116</td>\n",
              "      <td>-85</td>\n",
              "      <td>-19</td>\n",
              "      <td>-61</td>\n",
              "      <td>-70</td>\n",
              "      <td>84</td>\n",
              "      <td>16</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.3</td>\n",
              "      <td>-34.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-75.7</td>\n",
              "      <td>-146.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>-36.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-71.2</td>\n",
              "      <td>-161.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>-30.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-39.6</td>\n",
              "      <td>-63.6</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.3</td>\n",
              "      <td>-28.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-44.2</td>\n",
              "      <td>-33.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>93</td>\n",
              "      <td>106</td>\n",
              "      <td>386</td>\n",
              "      <td>218</td>\n",
              "      <td>63</td>\n",
              "      <td>54</td>\n",
              "      <td>29</td>\n",
              "      <td>-22</td>\n",
              "      <td>43</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.9</td>\n",
              "      <td>94.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.9</td>\n",
              "      <td>-6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.8</td>\n",
              "      <td>17.5</td>\n",
              "      <td>56.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.7</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>25.0</td>\n",
              "      <td>46.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>79</td>\n",
              "      <td>127</td>\n",
              "      <td>364</td>\n",
              "      <td>138</td>\n",
              "      <td>78</td>\n",
              "      <td>28</td>\n",
              "      <td>79</td>\n",
              "      <td>52</td>\n",
              "      <td>47</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>38.3</td>\n",
              "      <td>60.9</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.6</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>44.0</td>\n",
              "      <td>60.8</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.7</td>\n",
              "      <td>26.7</td>\n",
              "      <td>38.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>21.3</td>\n",
              "      <td>32.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows Ã— 278 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  sex  height  ...  Amp_V6_T_wave  Amp_V6_QRSA  Amp_V6_QRSTA\n",
              "0     75    0     190  ...            2.9         23.3          49.4\n",
              "1     56    1     165  ...            2.1         20.4          38.8\n",
              "2     54    0     172  ...            3.4         12.3          49.0\n",
              "3     55    0     175  ...            2.6         34.6          61.6\n",
              "4     75    0     190  ...            3.9         25.4          62.8\n",
              "..   ...  ...     ...  ...            ...          ...           ...\n",
              "447   53    1     160  ...            0.6         -4.4          -0.5\n",
              "448   37    0     190  ...            2.4         38.0          62.4\n",
              "449   36    0     166  ...            1.0        -44.2         -33.2\n",
              "450   32    1     155  ...            2.4         25.0          46.6\n",
              "451   78    1     160  ...            1.6         21.3          32.8\n",
              "\n",
              "[452 rows x 278 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK6mi0y3yJNG",
        "outputId": "733a9c75-7868-49ea-cee3-7afd183cf263"
      },
      "source": [
        "Data_X.dtypes"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                 int64\n",
              "sex                 int64\n",
              "height              int64\n",
              "weight              int64\n",
              "QRS_duration        int64\n",
              "                   ...   \n",
              "Amp_V6_S'_wave      int64\n",
              "Amp_V6_P_wave     float64\n",
              "Amp_V6_T_wave     float64\n",
              "Amp_V6_QRSA       float64\n",
              "Amp_V6_QRSTA      float64\n",
              "Length: 279, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5nCDfMouxNb"
      },
      "source": [
        "# Handling missing value\n",
        "We are imputing mean in place of missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBuB1DuEwNR_",
        "outputId": "09791403-7309-4dde-ba58-56e0c393684e"
      },
      "source": [
        "!pip install scikit-learn"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_wpIdQIuxNb",
        "outputId": "22e4eaae-f8a1-437a-c375-54a062dac7f6"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "z=SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(Data_X)\n",
        "Data_X = pd.DataFrame(data=z,columns=Data_X.columns.values)\n",
        "Data_X.isnull().sum()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age               0\n",
              "sex               0\n",
              "height            0\n",
              "weight            0\n",
              "QRS_duration      0\n",
              "                 ..\n",
              "Amp_V6_S'_wave    0\n",
              "Amp_V6_P_wave     0\n",
              "Amp_V6_T_wave     0\n",
              "Amp_V6_QRSA       0\n",
              "Amp_V6_QRSTA      0\n",
              "Length: 279, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ-6ZnTJzrN2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1-T116nuxNb"
      },
      "source": [
        "#  Good evaluation strategy\n",
        "As the dependent variabe is a categorical variable we will be using classification models. The best evaluation strategy for classification models is comparing the precision and recall. We know for a fact that R-sqaured and MSE scores are used extensively for checking the accuracy of a regression model where independent variable is a continous. However when we run classification models precision and recall are the best estimators of accuracy. Our main aim is to reduce the recall by improving the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kKI5M5HuxNb"
      },
      "source": [
        "# Spliting down into both train and test data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBmbh6l5uxNc",
        "outputId": "bc8e471b-6116-4639-c359-23891a825d88"
      },
      "source": [
        "data_train_x, data_test_x, data_train_y, data_test_y = train_test_split(Data_X, Data_Y\n",
        "                                                                        , random_state=2)\n",
        "# Scaling the data (MIN MAX Scaling)\n",
        "print('Shape of train {}, shape of test {}'.format(data_train_x.shape, data_test_x.shape))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train (339, 279), shape of test (113, 279)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3SPqBUkuxNc"
      },
      "source": [
        "# Scaling\n",
        "As the variables are on different scale it will be helpful if we bring them all on the same scale. Scaling improves the performance of the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qm67D2tuxNc"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#MinMax\n",
        "MinMax = MinMaxScaler(feature_range= (0,1))\n",
        "data_train_x = MinMax.fit_transform(data_train_x)\n",
        "data_test_x = MinMax.transform(data_test_x)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8SZLaE9uxNc"
      },
      "source": [
        "# 2. Modeling\n",
        "After taking care of the data we will be starting with the model creation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl2S4zdsuxNc"
      },
      "source": [
        "# KNN Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmJ5_AaAuxNc",
        "outputId": "66fae4de-6c4b-4c9f-bfdd-b6be1171cf02"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "## We are creating a grid for which all n_neighbors values are to be used for cross validation\n",
        "\n",
        "param_grid={'weights':['distance', 'uniform'], 'n_neighbors':range(1,100)}\n",
        "\n",
        "## Using Grid search for exhaustive searching\n",
        "\n",
        "grid_search = GridSearchCV( KNeighborsClassifier(),param_grid, cv = 10)\n",
        "grid_search.fit(data_train_x, data_train_y)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
              "                                            metric='minkowski',\n",
              "                                            metric_params=None, n_jobs=None,\n",
              "                                            n_neighbors=5, p=2,\n",
              "                                            weights='uniform'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'n_neighbors': range(1, 100),\n",
              "                         'weights': ['distance', 'uniform']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "s_Sy8GXEuxNd",
        "outputId": "a0932757-84a9-4328-e448-afa602038d45"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "train_Rsquare = grid_search.score(data_train_x, data_train_y)\n",
        "test_Rsquare = grid_search.score(data_test_x, data_test_y)\n",
        "train_MSE = mean_squared_error(data_train_y, grid_search.predict(data_train_x))\n",
        "test_MSE = mean_squared_error(data_test_y, grid_search.predict(data_test_x))\n",
        "output = output.append(pd.Series({'model':'KNN Classifier','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
        "output"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>train_Rsquare</th>\n",
              "      <th>test_Rsquare</th>\n",
              "      <th>train_MSE</th>\n",
              "      <th>test_MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN Classifier</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.504425</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.973451</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
              "0  KNN Classifier            1.0      0.504425        0.0  25.973451"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUMkVMxmuxNd"
      },
      "source": [
        "# R-squared, MSE vs precision, Recall\n",
        "We know for a fact that R-sqaured and MSE scores are used extensively for checking the accuracy of a regression model where independent variable is a continous. However when we run classification models precision and recall are the best estimators of accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhFGgtdVuxNd",
        "outputId": "27d2bda8-5da9-459e-e8e4-7123eb2ab01b"
      },
      "source": [
        "pd.DataFrame(grid_search.cv_results_)\n",
        "print(grid_search.best_estimator_)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
            "                     weights='distance')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2ANXjTXuxNe",
        "outputId": "bff1a379-4116-424d-b969-4bb4ebbfd038"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
        "           weights='distance')\n",
        "knn.fit(data_train_x, data_train_y)\n",
        "pred = knn.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.51      0.96      0.67        57\n",
            "           2       0.00      0.00      0.00        14\n",
            "           3       0.00      0.00      0.00         6\n",
            "           4       1.00      0.25      0.40         4\n",
            "           5       0.00      0.00      0.00         4\n",
            "           6       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.00      0.00      0.00         4\n",
            "          10       1.00      0.11      0.20         9\n",
            "          15       0.00      0.00      0.00         2\n",
            "          16       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.50       113\n",
            "   macro avg       0.23      0.12      0.12       113\n",
            "weighted avg       0.37      0.50      0.37       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asu-bKyfuxNe"
      },
      "source": [
        "## Output Evaluation\n",
        "In the whole process of model creation, our aim will be to achieve maximum Precision (no false positive) and maximum Recall (no false negative) there needs to be an absence of type I and II errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZm8NDxIuxNe"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5HbsN1ZuxNe",
        "outputId": "abef2415-752b-41ad-ce01-21ef1e38a02b"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
        "\n",
        "grid_search_log = GridSearchCV(LogisticRegression(penalty='l2'), param_grid, cv=5)\n",
        "grid_search_log.fit(data_train_x, data_train_y)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "uKVfVDYfuxNf",
        "outputId": "377ae2e6-0e5f-48f4-fd56-f038b11d1634"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "train_Rsquare = grid_search_log.score(data_train_x, data_train_y)\n",
        "test_Rsquare = grid_search_log.score(data_test_x, data_test_y)\n",
        "train_MSE = mean_squared_error(data_train_y, grid_search_log.predict(data_train_x))\n",
        "test_MSE = mean_squared_error(data_test_y, grid_search_log.predict(data_test_x))\n",
        "output = output.append(pd.Series({'model':'Logistic Regression','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
        "output"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>train_Rsquare</th>\n",
              "      <th>test_Rsquare</th>\n",
              "      <th>train_MSE</th>\n",
              "      <th>test_MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN Classifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.504425</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>25.973451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.840708</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>9.39528</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
              "0       KNN Classifier       1.000000      0.504425    0.00000  25.973451\n",
              "1  Logistic Regression       0.840708      0.690265    9.39528  20.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t631Oj3suxNf",
        "outputId": "6b3d8f40-adb9-4c4c-9a72-d44abfd052e7"
      },
      "source": [
        "pd.DataFrame(grid_search_log.cv_results_)\n",
        "print(grid_search_log.best_estimator_)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HY2sZEVuxNf",
        "outputId": "aea88b06-cae3-4f41-d1e6-0f94f568b1cf"
      },
      "source": [
        "log = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
        "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
        "          verbose=0, warm_start=False)\n",
        "log.fit(data_train_x, data_train_y)\n",
        "pred = log.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.69      0.96      0.80        57\n",
            "           2       0.55      0.43      0.48        14\n",
            "           3       1.00      1.00      1.00         6\n",
            "           4       0.75      0.75      0.75         4\n",
            "           5       0.00      0.00      0.00         4\n",
            "           6       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       1.00      0.25      0.40         4\n",
            "          10       0.78      0.78      0.78         9\n",
            "          15       0.00      0.00      0.00         2\n",
            "          16       1.00      0.17      0.29         6\n",
            "\n",
            "    accuracy                           0.70       113\n",
            "   macro avg       0.52      0.39      0.41       113\n",
            "weighted avg       0.64      0.70      0.64       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ucIZQ5fuxNf"
      },
      "source": [
        "# Linear Supprt Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nFOpuoPuxNf",
        "outputId": "baf2f342-467f-4f61-8779-005ba2d54995"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter':[1000,10000] }\n",
        "\n",
        "grid_search_SVC = GridSearchCV(LinearSVC(random_state=0), param_grid, cv=5)\n",
        "grid_search_SVC.fit(data_train_x, data_train_y)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                                 fit_intercept=True, intercept_scaling=1,\n",
              "                                 loss='squared_hinge', max_iter=1000,\n",
              "                                 multi_class='ovr', penalty='l2',\n",
              "                                 random_state=0, tol=0.0001, verbose=0),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000],\n",
              "                         'max_iter': [1000, 10000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "5boM42UyuxNg",
        "outputId": "bc4bba51-5bb5-462e-ba03-af5e5192399c"
      },
      "source": [
        "train_Rsquare = grid_search_SVC.score(data_train_x, data_train_y)\n",
        "test_Rsquare = grid_search_SVC.score(data_test_x, data_test_y)\n",
        "train_MSE = mean_squared_error(data_train_y, grid_search_SVC.predict(data_train_x))\n",
        "test_MSE = mean_squared_error(data_test_y, grid_search_SVC.predict(data_test_x))\n",
        "output = output.append(pd.Series({'model':'Linear SVC','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
        "output"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>train_Rsquare</th>\n",
              "      <th>test_Rsquare</th>\n",
              "      <th>train_MSE</th>\n",
              "      <th>test_MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN Classifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.504425</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.973451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.840708</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>9.395280</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Linear SVC</td>\n",
              "      <td>0.828909</td>\n",
              "      <td>0.699115</td>\n",
              "      <td>10.351032</td>\n",
              "      <td>17.548673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
              "0       KNN Classifier       1.000000      0.504425   0.000000  25.973451\n",
              "1  Logistic Regression       0.840708      0.690265   9.395280  20.000000\n",
              "2           Linear SVC       0.828909      0.699115  10.351032  17.548673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytwJXU2DuxNg",
        "outputId": "65b59d09-24e4-431a-c859-e9bd493b9f81"
      },
      "source": [
        "pd.DataFrame(grid_search_SVC.cv_results_)\n",
        "print(grid_search_SVC.best_estimator_)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "          verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bOVuzuxuxNg",
        "outputId": "8d8f1a70-a5ed-462c-ce30-00e1fc1e7ef4"
      },
      "source": [
        "linearsvc = LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
        "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
        "     verbose=0)\n",
        "linearsvc.fit(data_train_x, data_train_y)\n",
        "pred = linearsvc.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.68      0.95      0.79        57\n",
            "           2       0.60      0.43      0.50        14\n",
            "           3       0.86      1.00      0.92         6\n",
            "           4       1.00      0.75      0.86         4\n",
            "           5       0.00      0.00      0.00         4\n",
            "           6       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.67      0.50      0.57         4\n",
            "          10       0.78      0.78      0.78         9\n",
            "          15       0.00      0.00      0.00         2\n",
            "          16       1.00      0.17      0.29         6\n",
            "\n",
            "    accuracy                           0.70       113\n",
            "   macro avg       0.51      0.42      0.43       113\n",
            "weighted avg       0.64      0.70      0.64       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKYe9uvruxNg"
      },
      "source": [
        "# Kerenilzed Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5O8WSnquxNg",
        "outputId": "c4c85420-a4f1-400f-f01b-ce606c03c672"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {'C':[0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'gamma':[0.001, 0.01, 0.1, 0.5, 1, 10]}\n",
        "\n",
        "grid_search_KSVC = GridSearchCV(SVC(kernel = 'rbf'), param_grid, cv=5)\n",
        "grid_search_KSVC.fit(data_train_x, data_train_y)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000],\n",
              "                         'gamma': [0.001, 0.01, 0.1, 0.5, 1, 10]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "Fj2zZtPVuxNg",
        "outputId": "6f3cafce-79d4-4819-94b4-6090c1da74fb"
      },
      "source": [
        "train_Rsquare = grid_search_KSVC.score(data_train_x, data_train_y)\n",
        "test_Rsquare = grid_search_KSVC.score(data_test_x, data_test_y)\n",
        "train_MSE = mean_squared_error(data_train_y, grid_search_KSVC.predict(data_train_x))\n",
        "test_MSE = mean_squared_error(data_test_y, grid_search_KSVC.predict(data_test_x))\n",
        "output = output.append(pd.Series({'model':'Kernel SVC','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
        "output"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>train_Rsquare</th>\n",
              "      <th>test_Rsquare</th>\n",
              "      <th>train_MSE</th>\n",
              "      <th>test_MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN Classifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.504425</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.973451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.840708</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>9.395280</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Linear SVC</td>\n",
              "      <td>0.828909</td>\n",
              "      <td>0.699115</td>\n",
              "      <td>10.351032</td>\n",
              "      <td>17.548673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kernel SVC</td>\n",
              "      <td>0.893805</td>\n",
              "      <td>0.707965</td>\n",
              "      <td>6.628319</td>\n",
              "      <td>23.070796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
              "0       KNN Classifier       1.000000      0.504425   0.000000  25.973451\n",
              "1  Logistic Regression       0.840708      0.690265   9.395280  20.000000\n",
              "2           Linear SVC       0.828909      0.699115  10.351032  17.548673\n",
              "3           Kernel SVC       0.893805      0.707965   6.628319  23.070796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d784z2r6uxNh",
        "outputId": "a65b06fc-4ce5-4383-b62f-777e2de94b08"
      },
      "source": [
        "pd.DataFrame(grid_search_KSVC.cv_results_)\n",
        "print(grid_search_KSVC.best_estimator_)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC(C=50, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xCsDTTQuxNh",
        "outputId": "78073cd5-522e-40f0-ca09-7ff2558ccaea"
      },
      "source": [
        "svc = SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
        "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
        "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "  tol=0.001, verbose=False)\n",
        "svc.fit(data_train_x, data_train_y)\n",
        "pred = svc.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.68      0.91      0.78        57\n",
            "           2       0.80      0.57      0.67        14\n",
            "           3       1.00      1.00      1.00         6\n",
            "           4       0.80      1.00      0.89         4\n",
            "           5       0.00      0.00      0.00         4\n",
            "           6       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.75      0.75      0.75         4\n",
            "          10       1.00      0.67      0.80         9\n",
            "          15       1.00      0.50      0.67         2\n",
            "          16       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.71       113\n",
            "   macro avg       0.55      0.49      0.50       113\n",
            "weighted avg       0.65      0.71      0.66       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF8MrPHNuxNh"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv5OWiH1uxNi",
        "outputId": "f7076513-2767-4d3a-831d-a45ea50e0b34"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "param_grid = {'max_features':[None,'auto', 'log2'], 'max_depth':[5,10,15,20,50]}\n",
        "\n",
        "grid_search_DT = GridSearchCV(DecisionTreeClassifier(random_state = 10), param_grid, cv=5)\n",
        "grid_search_DT.fit(data_train_x, data_train_y)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=10,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [5, 10, 15, 20, 50],\n",
              "                         'max_features': [None, 'auto', 'log2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "DS43lWEsuxNi",
        "outputId": "44e61172-c042-4b9a-ef80-5ff139443a8f"
      },
      "source": [
        "train_Rsquare = grid_search_DT.score(data_train_x, data_train_y)\n",
        "test_Rsquare = grid_search_DT.score(data_test_x, data_test_y)\n",
        "train_MSE = mean_squared_error(data_train_y, grid_search_DT.predict(data_train_x))\n",
        "test_MSE = mean_squared_error(data_test_y, grid_search_DT.predict(data_test_x))\n",
        "output = output.append(pd.Series({'model':'Decision Tree Classifier','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
        "output"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>train_Rsquare</th>\n",
              "      <th>test_Rsquare</th>\n",
              "      <th>train_MSE</th>\n",
              "      <th>test_MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN Classifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.504425</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.973451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.840708</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>9.395280</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Linear SVC</td>\n",
              "      <td>0.828909</td>\n",
              "      <td>0.699115</td>\n",
              "      <td>10.351032</td>\n",
              "      <td>17.548673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kernel SVC</td>\n",
              "      <td>0.893805</td>\n",
              "      <td>0.707965</td>\n",
              "      <td>6.628319</td>\n",
              "      <td>23.070796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.955752</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>4.315634</td>\n",
              "      <td>20.371681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
              "0            KNN Classifier       1.000000      0.504425   0.000000  25.973451\n",
              "1       Logistic Regression       0.840708      0.690265   9.395280  20.000000\n",
              "2                Linear SVC       0.828909      0.699115  10.351032  17.548673\n",
              "3                Kernel SVC       0.893805      0.707965   6.628319  23.070796\n",
              "4  Decision Tree Classifier       0.955752      0.690265   4.315634  20.371681"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq70s9tDuxNi",
        "outputId": "cb3fa872-a3b5-46ba-9d31-47a2af387271"
      },
      "source": [
        "pd.DataFrame(grid_search_DT.cv_results_)\n",
        "print(grid_search_DT.best_estimator_)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=10, splitter='best')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FnQZnyeuxNi",
        "outputId": "6076117b-6cfe-4531-b24a-e1258b12efc9"
      },
      "source": [
        "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
        "            max_features=None, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
        "            splitter='best')\n",
        "dt.fit(data_train_x, data_train_y)\n",
        "pred = dt.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.78      0.88      0.83        57\n",
            "           2       0.78      0.50      0.61        14\n",
            "           3       0.67      0.67      0.67         6\n",
            "           4       0.40      0.50      0.44         4\n",
            "           5       0.00      0.00      0.00         4\n",
            "           6       0.71      0.83      0.77         6\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.00      0.00      0.00         4\n",
            "          10       0.50      0.89      0.64         9\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         2\n",
            "          16       0.67      0.33      0.44         6\n",
            "\n",
            "    accuracy                           0.69       113\n",
            "   macro avg       0.38      0.38      0.37       113\n",
            "weighted avg       0.65      0.69      0.66       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py:319: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAcLad0FuxNi"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__ehs4x1uxNj",
        "outputId": "e555b605-b475-4ea7-f7b2-09ced2320a5a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "#Tuning ridge on new dataset\n",
        "param_grid = {\"max_depth\": [3, 5],\n",
        "              \"max_features\": sp_randint(1, 40),\n",
        "              \"min_samples_split\": sp_randint(2, 30),\n",
        "              \"min_samples_leaf\": sp_randint(1, 20),\n",
        "              \"bootstrap\": [True, False]}\n",
        "grid_search_RF = RandomizedSearchCV(RandomForestClassifier(n_estimators=1000), param_distributions=param_grid,\n",
        "                                   n_iter=30, random_state=0,n_jobs=-1)\n",
        "grid_search_RF.fit(data_train_x, data_train_y)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=None, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=1000,\n",
              "                                                    n_...\n",
              "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f8247173490>,\n",
              "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f8247121390>,\n",
              "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f82471734d0>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMYICaSwuxNj",
        "outputId": "965d6567-cb5d-4f31-ecae-278ae362ab90"
      },
      "source": [
        "train_Rsquare = grid_search_RF.score(data_train_x, data_train_y)\n",
        "test_Rsquare = grid_search_RF.score(data_test_x, data_test_y)\n",
        "train_MSE = mean_squared_error(data_train_y, grid_search_RF.predict(data_train_x))\n",
        "test_MSE = mean_squared_error(data_test_y, grid_search_RF.predict(data_test_x))\n",
        "output = output.append(pd.Series({'model':'Random Forest Classifier','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>train_Rsquare</th>\n",
              "      <th>test_Rsquare</th>\n",
              "      <th>train_MSE</th>\n",
              "      <th>test_MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN Classifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.504425</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.973451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.823009</td>\n",
              "      <td>0.699115</td>\n",
              "      <td>9.351032</td>\n",
              "      <td>17.991150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Linear SVC</td>\n",
              "      <td>0.828909</td>\n",
              "      <td>0.699115</td>\n",
              "      <td>10.351032</td>\n",
              "      <td>17.548673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kernel SVC</td>\n",
              "      <td>0.893805</td>\n",
              "      <td>0.707965</td>\n",
              "      <td>6.628319</td>\n",
              "      <td>23.070796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.958702</td>\n",
              "      <td>0.663717</td>\n",
              "      <td>4.126844</td>\n",
              "      <td>21.292035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.755162</td>\n",
              "      <td>0.637168</td>\n",
              "      <td>17.731563</td>\n",
              "      <td>22.663717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
              "0            KNN Classifier       1.000000      0.504425   0.000000  25.973451\n",
              "1       Logistic Regression       0.823009      0.699115   9.351032  17.991150\n",
              "2                Linear SVC       0.828909      0.699115  10.351032  17.548673\n",
              "3                Kernel SVC       0.893805      0.707965   6.628319  23.070796\n",
              "4  Decision Tree Classifier       0.958702      0.663717   4.126844  21.292035\n",
              "5  Random Forest Classifier       0.755162      0.637168  17.731563  22.663717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j77b0-S7uxNj",
        "outputId": "734cf6c9-25d7-4230-a5c8-16cf5b38b761"
      },
      "source": [
        "pd.DataFrame(grid_search_RF.cv_results_)\n",
        "print(grid_search_RF.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
            "            max_depth=5, max_features=36, max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=7, min_samples_split=25,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEJPpB2-uxNj",
        "outputId": "f826d043-b7ba-42d8-f457-223276345d64"
      },
      "source": [
        "rf = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
        "            max_depth=5, max_features=36, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=7, min_samples_split=25,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0,\n",
        "            warm_start=False)\n",
        "rf.fit(data_train_x, data_train_y)\n",
        "pred = rf.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.64      0.98      0.78        57\n",
            "          2       0.58      0.50      0.54        14\n",
            "          3       1.00      0.50      0.67         6\n",
            "          4       0.00      0.00      0.00         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       0.00      0.00      0.00         4\n",
            "         10       0.73      0.89      0.80         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.51      0.65      0.56       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdV1OJJZuxNj"
      },
      "source": [
        "# 3. Bagging\n",
        "We will be using bagging to improve our earlier model with best parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqF4JV2CuxNj"
      },
      "source": [
        "##   KNN with bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_nQSn6AuxNk",
        "outputId": "faf1eb40-9019-47bd-da0b-70ea653e6eb1"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "KNN_bagging = BaggingClassifier(knn, n_estimators = 100, bootstrap = True)\n",
        "KNN_bagging.fit(data_train_x,data_train_y)\n",
        "pred = KNN_bagging.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.51      0.96      0.67        57\n",
            "          2       0.00      0.00      0.00        14\n",
            "          3       0.00      0.00      0.00         6\n",
            "          4       1.00      0.25      0.40         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       0.00      0.00      0.00         4\n",
            "         10       1.00      0.11      0.20         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.37      0.50      0.37       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX6NY0BiuxNk"
      },
      "source": [
        "# Logistic regression with bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7oo8cttuxNk",
        "outputId": "1e3dfff3-e43e-45e0-9df0-9aeee530d243"
      },
      "source": [
        "log_bagging = BaggingClassifier(log , n_estimators = 100, max_features = 200 ,bootstrap = True, oob_score = True)\n",
        "log_bagging.fit(data_train_x, data_train_y)\n",
        "pred = log_bagging.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.62      0.98      0.76        57\n",
            "          2       0.44      0.29      0.35        14\n",
            "          3       1.00      0.83      0.91         6\n",
            "          4       1.00      0.50      0.67         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       0.00      0.00      0.00         4\n",
            "         10       0.67      0.44      0.53         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.51      0.63      0.54       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcNBtfRruxNk"
      },
      "source": [
        "# Linear SVC with bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZBUTSYvuxNk",
        "outputId": "47a564e8-4d39-425b-e86a-e757ca6a76ab"
      },
      "source": [
        "linearsvc_bagging = BaggingClassifier(linearsvc , n_estimators = 100, max_features = 200 ,\n",
        "                                      bootstrap = True, oob_score = True)\n",
        "linearsvc_bagging.fit(data_train_x, data_train_y)\n",
        "pred = linearsvc_bagging.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.65      0.96      0.78        57\n",
            "          2       0.57      0.29      0.38        14\n",
            "          3       0.86      1.00      0.92         6\n",
            "          4       1.00      0.75      0.86         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       0.67      0.50      0.57         4\n",
            "         10       0.75      0.67      0.71         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.57      0.67      0.60       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7SWrFa9uxNk"
      },
      "source": [
        "# Kernalized SVC with bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVttakYFuxNl",
        "outputId": "931e6c16-6cda-4b59-bb47-04ed849d3fc2"
      },
      "source": [
        "svc_bagging = BaggingClassifier(svc , n_estimators = 100, max_features = 200 ,\n",
        "                                      bootstrap = True, oob_score = True)\n",
        "svc_bagging.fit(data_train_x, data_train_y)\n",
        "pred = svc_bagging.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.66      0.96      0.79        57\n",
            "          2       0.70      0.50      0.58        14\n",
            "          3       1.00      1.00      1.00         6\n",
            "          4       0.80      1.00      0.89         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       0.75      0.75      0.75         4\n",
            "         10       1.00      0.56      0.71         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.61      0.71      0.64       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBYHBuxxuxNl"
      },
      "source": [
        "# Decision Tree with bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27T7HoHAuxNl",
        "outputId": "66b7b796-033f-40c9-907a-bd688cd7a822"
      },
      "source": [
        "dt_bagging = BaggingClassifier(dt , n_estimators = 100, max_features = 200 ,\n",
        "                                      bootstrap = True, oob_score = True)\n",
        "dt_bagging.fit(data_train_x, data_train_y)\n",
        "pred = dt_bagging.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.73      0.95      0.82        57\n",
            "          2       0.62      0.57      0.59        14\n",
            "          3       1.00      0.50      0.67         6\n",
            "          4       1.00      0.25      0.40         4\n",
            "          5       1.00      0.25      0.40         4\n",
            "          6       0.83      0.83      0.83         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       1.00      0.75      0.86         4\n",
            "         10       0.67      0.89      0.76         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.70      0.73      0.69       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxQxiV3kuxNl"
      },
      "source": [
        "# Random forest with bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrxWfjh0uxNl",
        "outputId": "e10aa871-015c-41e4-9ac5-fcdb58b3d1cc"
      },
      "source": [
        "rf_bagging = BaggingClassifier(rf , n_estimators = 100, max_features = 200 ,\n",
        "                                      bootstrap = True, oob_score = True)\n",
        "rf_bagging.fit(data_train_x, data_train_y)\n",
        "pred = rf_bagging.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.63      1.00      0.77        57\n",
            "          2       0.60      0.43      0.50        14\n",
            "          3       1.00      0.33      0.50         6\n",
            "          4       0.00      0.00      0.00         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       0.00      0.00      0.00         4\n",
            "         10       0.80      0.89      0.84         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.51      0.65      0.54       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jLvBN7VuxNl"
      },
      "source": [
        "# Boosting\n",
        "The main idea behind using boosting is to convert weak learners "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vppyr1jAuxNl"
      },
      "source": [
        "# Ada boosting with Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7nHYsVLuxNm",
        "outputId": "1d080336-881f-42e2-c9c6-28b4ab8f17d0"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
        "adaboost_log = GridSearchCV(AdaBoostClassifier(base_estimator = log,random_state = 0), param_grid, cv=5,return_train_score=True)\n",
        "adaboost_log.fit(data_train_x, data_train_y)\n",
        "\n",
        "pred = adaboost_log.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.54      1.00      0.70        57\n",
            "          2       0.67      0.14      0.24        14\n",
            "          3       1.00      0.17      0.29         6\n",
            "          4       0.00      0.00      0.00         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       0.00      0.00      0.00         4\n",
            "         10       0.67      0.22      0.33         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.46      0.55      0.43       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jn8VkRRuxNm"
      },
      "source": [
        "# Ada boosting with Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdY2Pa3BuxNm",
        "outputId": "562bedbb-45fc-4dc8-aefd-3332ce5c094c"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
        "adaboost_svc = GridSearchCV(AdaBoostClassifier(base_estimator = linearsvc,random_state = 0, algorithm='SAMME'),\n",
        "                            param_grid, cv=5,return_train_score=True)\n",
        "adaboost_svc.fit(data_train_x, data_train_y)\n",
        "\n",
        "pred = adaboost_svc.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.68      0.95      0.79        57\n",
            "          2       0.60      0.43      0.50        14\n",
            "          3       0.86      1.00      0.92         6\n",
            "          4       1.00      0.75      0.86         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       0.67      0.50      0.57         4\n",
            "         10       0.78      0.78      0.78         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       1.00      0.17      0.29         6\n",
            "\n",
            "avg / total       0.64      0.70      0.64       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77XuXbP1uxNm"
      },
      "source": [
        "# Ada boosting with Kernalized SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDcY4jPruxNm",
        "outputId": "c6249088-41e4-4821-a20d-d493f37f872f"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
        "adaboost_ksvc = GridSearchCV(AdaBoostClassifier(base_estimator = svc,random_state = 0, algorithm='SAMME'),\n",
        "                            param_grid, cv=5,return_train_score=True)\n",
        "adaboost_ksvc.fit(data_train_x, data_train_y)\n",
        "\n",
        "pred = adaboost_ksvc.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.50      1.00      0.67        57\n",
            "          2       0.00      0.00      0.00        14\n",
            "          3       0.00      0.00      0.00         6\n",
            "          4       0.00      0.00      0.00         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       0.00      0.00      0.00         4\n",
            "         10       0.00      0.00      0.00         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.25      0.50      0.34       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaxUKBWDuxNm"
      },
      "source": [
        "# Ada Boosting with Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pR4bQesuxNn",
        "outputId": "605e9d97-11ca-4678-81c3-110129b6d3f7"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
        "adaboost_dt = GridSearchCV(AdaBoostClassifier(base_estimator = dt,random_state = 0),\n",
        "                            param_grid, cv=5,return_train_score=True)\n",
        "adaboost_dt.fit(data_train_x, data_train_y)\n",
        "\n",
        "pred = adaboost_dt.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.75      0.82      0.78        57\n",
            "          2       0.50      0.50      0.50        14\n",
            "          3       0.00      0.00      0.00         6\n",
            "          4       0.50      0.75      0.60         4\n",
            "          5       1.00      0.25      0.40         4\n",
            "          6       0.67      0.67      0.67         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       1.00      0.50      0.67         4\n",
            "         10       0.44      0.78      0.56         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.60      0.63      0.60       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLScPQqTuxNn"
      },
      "source": [
        "# Ada Boosting with Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSVPPpu6uxNn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK_2DQnwuxNn"
      },
      "source": [
        "# Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN2ni-1tuxNn",
        "outputId": "9efdda89-bbba-4555-f135-ff9cec09bdf5"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "model = GradientBoostingClassifier(random_state=10, n_estimators= 500)\n",
        "\n",
        "param_grid = {'max_features':['auto', 'log2'], 'learning_rate' : [0.01,0.1], 'max_depth':[5,10,15,30,50]}\n",
        "\n",
        "grid_search_gb = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search_gb.fit(data_train_x, data_train_y)\n",
        "pred = grid_search_gb.predict(data_test_x)\n",
        "print(classification_report(data_test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.66      0.98      0.79        57\n",
            "          2       0.55      0.43      0.48        14\n",
            "          3       1.00      0.50      0.67         6\n",
            "          4       1.00      0.25      0.40         4\n",
            "          5       0.00      0.00      0.00         4\n",
            "          6       0.00      0.00      0.00         6\n",
            "          8       0.00      0.00      0.00         1\n",
            "          9       1.00      0.50      0.67         4\n",
            "         10       0.64      0.78      0.70         9\n",
            "         15       0.00      0.00      0.00         2\n",
            "         16       0.00      0.00      0.00         6\n",
            "\n",
            "avg / total       0.57      0.66      0.59       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wChdqLxuxNn"
      },
      "source": [
        "# Comparing bagging and boosting models with previous one's\n",
        "When we compare the precision and recall of earlier model with models with baaging and boosting we see that the new models accuracy has dropped. Bagging and boosting are used to lower the bias of the model, When we apply boost we introduce the risk of overfitting. Overfitting ulitmately lowers the accuracy estimated by cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUNDwbJTuxNn"
      },
      "source": [
        "# 4. PCA\n",
        "We will be using principal component analysis for data reduction. We have 278 variables which is increasing the complexity of the models. PCA reduces the complexity of the model by only considering the important variables and thus reducing the overall data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV8KSe7AuxNo"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(0.95)\n",
        "pca.fit(Data_X)\n",
        "Data_X_PCA = pca.transform(Data_X)\n",
        "\n",
        "data_train_x_pca, data_test_x_pca, data_train_y_pca, data_test_y_pca = train_test_split(Data_X_PCA, Data_Y, random_state = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGObYKwLuxNo"
      },
      "source": [
        "#Checking results of 2 scalars\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#MinMax\n",
        "MinMax = MinMaxScaler(feature_range= (0,1))\n",
        "data_train_x_pca = MinMax.fit_transform(data_train_x_pca)\n",
        "data_test_x_pca = MinMax.transform(data_test_x_pca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUNcszvZuxNo"
      },
      "source": [
        "# KNN with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtaAiK2GuxNo",
        "outputId": "2d1baed5-ba66-4a39-a4b4-a54d0be77739"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "param_grid = {'weights':['distance', 'uniform'], 'n_neighbors':range(3,100)}\n",
        "\n",
        "grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5,return_train_score=True)\n",
        "grid_search_knn.fit(data_train_x_pca, data_train_y_pca)\n",
        "pd.DataFrame(grid_search_knn.cv_results_)\n",
        "print(grid_search_knn.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5368731563421829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEqvytqEuxNo",
        "outputId": "01d69f0c-4534-4adf-80bb-0c11e38590bd"
      },
      "source": [
        "print(grid_search_knn.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
            "           weights='distance')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5-o_ZJMuxNo",
        "outputId": "b39e9e1b-442a-4187-9e39-5dc884da2349"
      },
      "source": [
        "knn_pca = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
        "           weights='distance')\n",
        "knn_pca.fit(data_train_x_pca, data_train_y_pca)\n",
        "pred = knn_pca.predict(data_test_x_pca)\n",
        "print(classification_report(data_test_y_pca,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.68      0.93      0.79        72\n",
            "          2       0.33      0.10      0.15        10\n",
            "          3       0.00      0.00      0.00         5\n",
            "          4       0.00      0.00      0.00         2\n",
            "          5       0.00      0.00      0.00         1\n",
            "          6       0.00      0.00      0.00         5\n",
            "         10       0.80      0.44      0.57         9\n",
            "         14       0.00      0.00      0.00         1\n",
            "         15       0.00      0.00      0.00         3\n",
            "         16       0.00      0.00      0.00         5\n",
            "\n",
            "avg / total       0.53      0.64      0.56       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFE6BHkGuxNp"
      },
      "source": [
        "# Logistic with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3l2PdiDuxNp",
        "outputId": "b2a51b46-ee4d-4dc0-c82e-304c3053f063"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {'C': range(1,100) }\n",
        "\n",
        "grid_search_log = GridSearchCV(LogisticRegression(penalty='l1'), param_grid, cv=5,return_train_score=True)\n",
        "grid_search_log.fit(data_train_x_pca, data_train_y_pca)\n",
        "pd.DataFrame(grid_search_log.cv_results_)\n",
        "print(grid_search_log.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWIsM6ITuxNp",
        "outputId": "198b1e59-4325-437d-c372-31ad2535416d"
      },
      "source": [
        "print(grid_search_log.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMfoqtlAuxNp",
        "outputId": "47405993-152b-4172-c0d1-84f53982143d"
      },
      "source": [
        "logistic_pca = LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
        "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
        "          verbose=0, warm_start=False)\n",
        "logistic_pca.fit(data_train_x_pca, data_train_y_pca)\n",
        "pred = logistic_pca.predict(data_test_x_pca)\n",
        "print(classification_report(data_test_y_pca,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.81      0.93      0.86        72\n",
            "          2       0.57      0.40      0.47        10\n",
            "          3       0.83      1.00      0.91         5\n",
            "          4       0.50      1.00      0.67         2\n",
            "          5       0.00      0.00      0.00         1\n",
            "          6       0.00      0.00      0.00         5\n",
            "         10       0.88      0.78      0.82         9\n",
            "         14       0.00      0.00      0.00         1\n",
            "         15       0.00      0.00      0.00         3\n",
            "         16       0.00      0.00      0.00         5\n",
            "\n",
            "avg / total       0.68      0.75      0.71       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iBfsH30uxNp"
      },
      "source": [
        "# Linear SVM with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psloVF9guxNp",
        "outputId": "8db4cf4f-d5e9-4130-d5b0-a5ef469a0b6f"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "param_grid = {'C': [0.0001,0.001,0.01,0.1,2,3,4,5,6,7,8,9], 'max_iter':[100,1000,10000] }\n",
        "\n",
        "grid_search_linearsvc = GridSearchCV(LinearSVC(random_state=0), param_grid, cv=5,return_train_score=True)\n",
        "grid_search_linearsvc.fit(data_train_x_pca, data_train_y_pca)\n",
        "pd.DataFrame(grid_search_linearsvc.cv_results_)\n",
        "print(grid_search_linearsvc.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=100,\n",
            "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "     verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMhL-uhfuxNp",
        "outputId": "96fc37f3-9054-4290-a2cc-c66870ae7c3e"
      },
      "source": [
        "linearsvc = LinearSVC(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='squared_hinge', max_iter=100,\n",
        "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
        "     verbose=0)\n",
        "linearsvc.fit(data_train_x_pca, data_train_y_pca)\n",
        "pred = linearsvc.predict(data_test_x_pca)\n",
        "print(classification_report(data_test_y_pca,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.81      0.92      0.86        72\n",
            "          2       0.57      0.40      0.47        10\n",
            "          3       0.83      1.00      0.91         5\n",
            "          4       0.50      1.00      0.67         2\n",
            "          5       0.00      0.00      0.00         1\n",
            "          6       0.00      0.00      0.00         5\n",
            "         10       0.75      0.67      0.71         9\n",
            "         14       0.00      0.00      0.00         1\n",
            "         15       0.00      0.00      0.00         3\n",
            "         16       0.00      0.00      0.00         5\n",
            "\n",
            "avg / total       0.68      0.73      0.70       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWwyYZO1uxNq"
      },
      "source": [
        "# Kernalized SVM with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drz_QrVvuxNq",
        "outputId": "a55c5749-38cc-4304-c2af-acfb08a35ab9"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {'C':[0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'gamma':[0.001, 0.01, 0.1, 0.5, 1, 10]}\n",
        "\n",
        "grid_search_svc = GridSearchCV(SVC(kernel = 'rbf'), param_grid, cv=5,return_train_score=True)\n",
        "grid_search_svc.fit(data_train_x_pca, data_train_y_pca)\n",
        "pd.DataFrame(grid_search_svc.cv_results_)\n",
        "print(grid_search_svc.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
            "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU7GiqwvuxNq",
        "outputId": "57e4a56d-93cb-49ab-9bd2-c7df62f6f242"
      },
      "source": [
        "svc = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
        "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
        "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "  tol=0.001, verbose=False)\n",
        "svc.fit(data_train_x_pca, data_train_y_pca)\n",
        "pred = svc.predict(data_test_x_pca)\n",
        "print(classification_report(data_test_y_pca,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.78      0.97      0.86        72\n",
            "          2       0.50      0.30      0.37        10\n",
            "          3       0.80      0.80      0.80         5\n",
            "          4       0.67      1.00      0.80         2\n",
            "          5       0.00      0.00      0.00         1\n",
            "          6       0.00      0.00      0.00         5\n",
            "         10       0.75      0.67      0.71         9\n",
            "         14       0.00      0.00      0.00         1\n",
            "         15       0.00      0.00      0.00         3\n",
            "         16       0.00      0.00      0.00         5\n",
            "\n",
            "avg / total       0.65      0.75      0.69       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SYpFvciuxNq"
      },
      "source": [
        "# Decision tree with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB32FyuKuxNq",
        "outputId": "843c45c5-4b08-48f3-a310-ca83fa3b828e"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "param_grid = {'max_features':['auto', 'log2'], 'max_depth':[3,5,7,9,10,11,13,15,20,50]}\n",
        "\n",
        "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state = 0), param_grid, cv=5,return_train_score=True)\n",
        "grid_search_dt.fit(data_train_x_pca, data_train_y_pca)\n",
        "pd.DataFrame(grid_search_dt.cv_results_)\n",
        "print(grid_search_dt.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
            "            max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
            "            splitter='best')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLqi1NX3uxNq",
        "outputId": "2f634843-e565-476e-f524-9e321407aafe"
      },
      "source": [
        "dt_pca = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
        "            max_features='auto', max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
        "            splitter='best')\n",
        "dt_pca.fit(data_train_x_pca, data_train_y_pca)\n",
        "pred = dt_pca.predict(data_test_x_pca)\n",
        "print(classification_report(data_test_y_pca,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.69      0.85      0.76        72\n",
            "          2       0.20      0.20      0.20        10\n",
            "          3       0.67      0.40      0.50         5\n",
            "          4       0.00      0.00      0.00         2\n",
            "          5       0.00      0.00      0.00         1\n",
            "          6       0.00      0.00      0.00         5\n",
            "         10       0.18      0.22      0.20         9\n",
            "         14       0.00      0.00      0.00         1\n",
            "         15       0.00      0.00      0.00         3\n",
            "         16       0.00      0.00      0.00         5\n",
            "\n",
            "avg / total       0.50      0.59      0.54       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ69tFwHuxNr"
      },
      "source": [
        "# Random Forest with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyr1Ew0iuxNr",
        "outputId": "5efa9b87-ad4c-4e34-88e6-7facdaa09715"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "#Tuning ridge on new dataset\n",
        "param_grid = {\"max_depth\": sp_randint(3, 9),\n",
        "              \"max_features\": sp_randint(1, 10),\n",
        "              \"min_samples_split\": sp_randint(2, 20),\n",
        "              \"min_samples_leaf\": sp_randint(1, 20),\n",
        "              \"bootstrap\": [True, False]}\n",
        "random_search_rf = RandomizedSearchCV(RandomForestClassifier(n_estimators=1000), param_distributions=param_grid,\n",
        "                                   n_iter=30, random_state=0,n_jobs=-1, cv= 5,return_train_score=True)\n",
        "random_search_rf.fit(data_train_x_pca, data_train_y_pca)\n",
        "pd.DataFrame(random_search_rf.cv_results_)\n",
        "print(random_search_rf.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
            "            max_depth=5, max_features=9, max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=2, min_samples_split=3,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz5BH4bUuxNr",
        "outputId": "04137a4c-ab90-407a-8d99-f094454b97af"
      },
      "source": [
        "rf_pca = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
        "            max_depth=5, max_features=9, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=2, min_samples_split=3,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0,\n",
        "            warm_start=False)\n",
        "rf_pca.fit(data_train_x_pca, data_train_y_pca)\n",
        "pred = rf_pca.predict(data_test_x_pca)\n",
        "print(classification_report(data_test_y_pca,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.75      0.92      0.83        72\n",
            "          2       0.50      0.50      0.50        10\n",
            "          3       0.75      0.60      0.67         5\n",
            "          4       0.00      0.00      0.00         2\n",
            "          5       0.00      0.00      0.00         1\n",
            "          6       0.00      0.00      0.00         5\n",
            "         10       0.36      0.44      0.40         9\n",
            "         14       0.00      0.00      0.00         1\n",
            "         15       0.00      0.00      0.00         3\n",
            "         16       0.00      0.00      0.00         5\n",
            "\n",
            "avg / total       0.58      0.69      0.63       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UpwyWfhuxNr"
      },
      "source": [
        "# Gradient boosting with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUVR92BHuxNr",
        "outputId": "43795a90-4f58-41aa-daac-f75dbc0a1137"
      },
      "source": [
        "param_grid = {\"max_depth\": sp_randint(5,30),\n",
        "              \"max_features\": sp_randint(1, 35),\n",
        "              \"min_samples_split\": sp_randint(2, 40),\n",
        "              \"min_samples_leaf\": sp_randint(1, 30),\n",
        "             'learning_rate': [0.01,0.001,0.1]}\n",
        "random_search_gb = RandomizedSearchCV(GradientBoostingClassifier(n_estimators=1000), param_distributions=param_grid,\n",
        "                                   n_iter=30, random_state=0,n_jobs=-1,cv= 5,return_train_score=True)\n",
        "random_search_gb.fit(data_train_x_pca, data_train_y_pca)\n",
        "pd.DataFrame(random_search_gb.cv_results_)\n",
        "print(random_search_gb.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.01, loss='deviance', max_depth=9,\n",
            "              max_features=6, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=7, min_samples_split=19,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
            "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
            "              warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6n2wv6-uxNs",
        "outputId": "a16912bc-008a-4a9a-8c86-95abbae6fcd7"
      },
      "source": [
        "gbc_pca = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
        "              learning_rate=0.01, loss='deviance', max_depth=9,\n",
        "              max_features=6, max_leaf_nodes=None,\n",
        "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "              min_samples_leaf=7, min_samples_split=19,\n",
        "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
        "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False)\n",
        "gbc_pca.fit(data_train_x_pca, data_train_y_pca)\n",
        "pred = gbc_pca.predict(data_test_x_pca)\n",
        "print(classification_report(data_test_y_pca,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.79      0.93      0.85        72\n",
            "          2       0.67      0.60      0.63        10\n",
            "          3       0.83      1.00      0.91         5\n",
            "          4       0.50      0.50      0.50         2\n",
            "          5       0.00      0.00      0.00         1\n",
            "          6       0.50      0.20      0.29         5\n",
            "         10       0.62      0.56      0.59         9\n",
            "         14       0.00      0.00      0.00         1\n",
            "         15       0.00      0.00      0.00         3\n",
            "         16       0.00      0.00      0.00         5\n",
            "\n",
            "avg / total       0.68      0.75      0.71       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwPGolRpuxNs"
      },
      "source": [
        "# ADA boosting with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ks5N60euxNs",
        "outputId": "fc4c3bbe-a451-4511-e0ba-d05bb17f9fa8"
      },
      "source": [
        "param_grid = {'learning_rate' :[0.0001,0.001,0.01,0.1,1,1.2,2] ,\n",
        "              \"algorithm\":['SAMME', 'SAMME.R']}\n",
        "random_search_ada = RandomizedSearchCV(AdaBoostClassifier(n_estimators = 1000), param_distributions=param_grid,\n",
        "                                   n_iter=10, random_state=0,n_jobs=-1,cv= 5,return_train_score=True)\n",
        "random_search_ada.fit(data_train_x_pca, data_train_y_pca)\n",
        "pd.DataFrame(random_search_ada.cv_results_)\n",
        "print(random_search_ada.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1,\n",
            "          n_estimators=1000, random_state=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuaT1sHMuxNs",
        "outputId": "0c669709-d621-48dc-9219-6ff7b04eceed"
      },
      "source": [
        "ada_pca = AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1,\n",
        "          n_estimators=1000, random_state=None)\n",
        "ada_pca.fit(data_train_x_pca, data_train_y_pca)\n",
        "pred = ada_pca.predict(data_test_x_pca)\n",
        "print(classification_report(data_test_y_pca,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.73      0.85      0.78        72\n",
            "          2       0.00      0.00      0.00        10\n",
            "          3       0.67      0.40      0.50         5\n",
            "          4       0.00      0.00      0.00         2\n",
            "          5       0.00      0.00      0.00         1\n",
            "          6       0.50      0.20      0.29         5\n",
            "          8       0.00      0.00      0.00         0\n",
            "          9       0.00      0.00      0.00         0\n",
            "         10       0.31      0.44      0.36         9\n",
            "         14       0.00      0.00      0.00         1\n",
            "         15       0.00      0.00      0.00         3\n",
            "         16       0.00      0.00      0.00         5\n",
            "\n",
            "avg / total       0.54      0.60      0.56       113\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhhirHzRuxNs"
      },
      "source": [
        "# Evaluation after PCA\n",
        "The models started performing better after we applied PCA on the original data. The reason behind this is, PCA reduces the complexity of the data. It creates components based on giving importance to variables with large variance and also the components which it creates are non collinear in nature which means it takes care of collinearity in large data set. PCA also improves the overall execution time and quality of the models and it is very beneficial when we are working with huge amount of variables.\n",
        "The Best model according to the precision and recall score is Kernalized SVM with PCA having accuracy of 75%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgBre5FeuxNs"
      },
      "source": [
        "## End"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haGqaHNPuxNs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}